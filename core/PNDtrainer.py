import torch
# from torch.utils.tensorboard import SummaryWriter
import os
from scipy.io import savemat
from tqdm import tqdm
import os.path as path
from PIL import Image
import itertools
from PNDNet.PNDNet import *
from utils.third import *
from utils.visual_tool import *
from utils.image_pool import ImagePool

import numpy as np
import matplotlib.pyplot as plt

class PND_NET_trainer(nn.Module):
    def __int__(self):
        super(PND_NET_trainer, self).__int__()

    def initial(self, opt, device, dataset, train_loder, val_loder=None):
        self.opt = opt
        self.device = device
        #dataset
        self.dataset = dataset
        self.train_loder = train_loder
        if val_loder:
            self.val_loder = val_loder
        else:
            self.val_loder = None

        if self.opt.FNetname=='Unet':
            self.CombineNet = CombineNet_Unet(self.opt).to(device=self.device)
        elif self.opt.FNetname == 'Map':
            self.CombineNet = CombineNet_Map(self.opt).to(device=self.device)
        else:
            raise NotImplementedError('FNetname: opt.DisType=Unet,Map ')

        self.DecompoNet = DecomposeNet(self.opt).to(device=self.device)

        # loss
        self.criterionIdt = torch.nn.L1Loss(reduction='mean')
        self.criterionCycle = torch.nn.L1Loss(reduction='mean')
        self.criterion_mse = nn.MSELoss()
        self.tv = TotalVariationLoss(c_img=1).to(device)
        self.criterionGAN = GANLoss(gan_mode='lsgan').to(device=self.device)

        self.fake_Xa_pool = ImagePool(self.opt.pool_size)
        self.fake_Xc_pool = ImagePool(self.opt.pool_size)

        # train loss logger
        # self.dis_writer = SummaryWriter(
        #     os.path.join(self.opt.loggerpath, 'dis'))
        # self.gen_writer = SummaryWriter(
        #     os.path.join(self.opt.loggerpath, 'gen'))
        self.GAN_loss_logger = np.zeros([self.opt.epochs, 1], dtype=np.float32)
        self.Dis_loss_logger = np.zeros([self.opt.epochs, 1], dtype=np.float32)
        self.Val_loss_logger = np.zeros([self.opt.epochs, 1], dtype=np.float32)

        # gaussian kernel
        self.GaussianFilter1 = GaussianFilterLayer(1, 5, 1, 1).to(self.device)
        self.GaussianFilter3 = GaussianFilterLayer(1, 5, 3, 1).to(self.device)

        self.FBPtool = FBP
        self.FPtool = FP


    def normalize(self, img):
        minval, mxaval = self.opt.dataMin, self.opt.dataMax
        img = torch.clamp(img,minval,mxaval,out=None)
        img = (img-minval)/(mxaval-minval)
        img = img*2.0-1.0
        return img

    def Renormalize(self, img):
        minval, mxaval = self.opt.dataMin, self.opt.dataMax
        img = img*0.5 + 0.5
        img = img*(mxaval-minval)+minval
        return img

    def set_requires_grad(self, nets, requires_grad=False):
        """Set requies_grad=Fasle for all the networks to avoid unnecessary computations
        Parameters:
            nets (network list)   -- a list of networks
            requires_grad (bool)  -- whether the networks require gradients or not
        """
        if not isinstance(nets, list):
            nets = [nets]
        for net in nets:
            if net is not None:
                for param in net.parameters():
                    param.requires_grad = requires_grad

    def backward_D_basic(self, netD, real, fake):
        """Calculate GAN loss for the discriminator

        Parameters:
            netD (network)      -- the discriminator D
            real (tensor array) -- real images
            fake (tensor array) -- images generated by a generator

        Return the discriminator loss.
        We also call loss_D.backward() to calculate the gradients.
        """

        real = self.normalize(real)
        fake = self.normalize(fake)

        # Real
        pred_real = netD(real)
        loss_D_real = self.criterionGAN(pred_real, True)
        # Fake
        pred_fake = netD(fake.detach())
        loss_D_fake = self.criterionGAN(pred_fake, False)
        # Combined loss and calculate gradients
        loss_D = (loss_D_real + loss_D_fake) * 0.5
        loss_D.backward()
        return loss_D

    def D_Xa_backward(self):
        fake_Xa = self.fake_Xa_pool.query(self.Icm)
        self.loss_D_Xa = self.backward_D_basic(self.netD_Xa, self.Im, fake_Xa)

    def D_Xc_backward(self):
        fake_Xc = self.fake_Xc_pool.query(self.Imc)
        self.loss_D_Xc = self.backward_D_basic(self.netD_Xc,self.Ic,fake_Xc)

    def _train_mode(self):
        self.CombineNet.train()
        self.DecompoNet.train()
        self.netD_Xa.train()
        self.netD_Xc.train()

    def _eval_mode(self):
        self.CombineNet.eval()
        self.DecompoNet.eval()
        self.netD_Xa.eval()
        self.netD_Xc.eval()

    def updata_lr_scheduler(self):
        self.scheduler_G.step()
        self.scheduler_D.step()

    def Generator_zero_grad(self):
        self.CombineNet.zero_grad()
        self.DecompoNet.zero_grad()

    def _saveModel(self, epoch):
        save_ckpt('{:s}/{:s}.pth'.format(self.opt.save_dir, self.opt.netD_name),
                  [('netD_Xc', self.netD_Xc), ('netD_Xa', self.netD_Xa)], [('optimizer', self.optimizer_D)], epoch)
        save_ckpt('{:s}/{:s}_epoch{:d}.pth'.format(self.opt.save_dir, self.opt.model_name, epoch),
                  [('model', self.DecompoNet), ('model2', self.CombineNet)], None, epoch)

    def _load_pertrain_model(self, genNet_pth, disNet_pth=None):
        load_ckpt(genNet_pth, [('model', self.DecompoNet), ('model2', self.CombineNet)])
        if disNet_pth is not None:
            load_ckpt(disNet_pth, [('netD_Xc', self.netD_Xc), ('netD_Xa', self.netD_Xa)])

    def Generator_backward(self):
        lambda_idt = self.opt.lambda_idt*self.opt.scaleLoss
        lambda_art = self.opt.lambda_art*self.opt.scaleLoss
        lambda_cycle = self.opt.lambda_cycle*self.opt.scaleLoss
        lambda_LI_prior = self.opt.lambda_LI_prior*self.opt.scaleLoss

        #identity loss
        if lambda_idt>0:
            Icc = self.DecompoNet.forward2(self.Ic)
            self.loss_idt = self.criterion_mse(Icc, self.Ic)
            # Xaa = self.DualModle2.forward2(self.Xa, self.NoMetalMask*0.001)
            # self.loss_idt = self.criterionMSE(Xcc,self.Xc)+self.criterionMSE(self.Xa,Xaa)
        else:
            self.loss_idt = 0

        # GAN loss
        self.loss_G_Xc = self.criterionGAN(self.netD_Xc(self.normalize(self.Imc)), True)
                         # + self.criterionGAN(self.netD_Xc(self.normalize(self.Isc)), True)*0.1
        self.loss_G_Xa = self.criterionGAN(self.netD_Xa(self.normalize(self.Icm)), True)

        # prior loss
        if self.opt.lambda_TV>0:
            BHC_tv = self.tv(self.Isc_inpaint)*self.opt.lambda_TV
        else:
            BHC_tv = 0.0
        loss_sino = self.criterionCycle(self.GaussianFilter1(self.SLI), self.GaussianFilter1(self.Ssc))
        self.loss_idt_LIMAR = loss_sino

        #cycle loss
        self.L_cycle = self.criterionCycle(self.Ic, self.Icmc)+self.criterionCycle(self.Im, self.Imcm)

        self.L_art = self.criterionCycle(self.aS, self.aS_bar)\
                     + self.criterionCycle(self.aI, self.aI_bar)

        #combined all loss
        self.loss_G = self.loss_G_Xa+self.loss_G_Xc\
                        +self.loss_idt*lambda_idt\
                        +self.loss_idt_LIMAR*lambda_LI_prior\
                        +self.L_cycle*lambda_cycle\
                        +self.L_art*lambda_art+BHC_tv
        self.loss_G.backward()

    def to_npy(self, *tensors, squeeze=False):
        if len(tensors) == 1:
            if squeeze:
                return tensors[0].detach().cpu().numpy().squeeze()
            else:
                return tensors[0].detach().cpu().numpy()
        else:
            if squeeze:
                return [t.detach().cpu().numpy().squeeze() for t in tensors]
            else:
                return [t.detach().cpu().numpy() for t in tensors]

    def get_visual(self, visual_dir, epoch, images, n_rows=4, normalize=True):
        if normalize: images = (images - 0) / (0.5 - 0)
        visuals = make_grid(images, nrow=images.shape[0] // n_rows, normalize=False)
        visuals = self.to_npy(visuals).transpose(1, 2, 0)
        visuals = (visuals * 255).astype(np.uint8)
        visual_file = path.join(visual_dir,
                                "epoch{}.png".format(epoch))
        Image.fromarray(visuals).convert('RGB').save(visual_file)

    def Model_train(self):
        dataType = torch.float32
        for epoch in range(self.opt.epochs):
            loop =  tqdm(enumerate(self.train_loder), total=len(self.dataset)/self.opt.batch_size)
            temp_GAN_loss = []
            temp_Dis_loss = []
            # gt,metal,XLI,mask_onlymetal,Sgt,Sma,SLI
            for step,(Xc, Xa, XLI, Mask, Sc, Sm, SLI) in loop:
                self._train_mode()
                self.Ic = Xc.to(device=self.device,dtype=dataType)
                self.Sm = Sm.to(device=self.device, dtype=dataType)
                self.SLI = SLI.to(device=self.device, dtype=dataType)
                self.Mask = Mask.to(device=self.device, dtype=dataType)
                self.Sc = Sc.to(device=self.device, dtype=dataType)
                self.Im = Xa.to(device=self.device, dtype=dataType)
                self.XLI = XLI.to(device=self.device, dtype=dataType)

                ############ model forward ##################
                # DecompoNet return: Ssc, Art_s, Isc, Imc, Art_i
                # aS = NSDNet(Sa), Ssc = Sa-aS, Isc = FBP(Ssc), Imc = IRNet(Isc), aI = Isc-Imc,
                self.Ssc, self.aS, self.Isc, self.Imc, self.aI = self.DecompoNet(self.Sm, self.Mask)

                if self.opt.lambda_TV>0:
                    Mt = self.FPtool(self.Mask)
                    Mt = (Mt>0.0).float()
                    S_inpaint = self.Sm - Mt*self.aS
                    self.Isc_inpaint = self.FBPtool(S_inpaint).div(self.dataset.imPixScale)

                # ------------Generator: Ic->Icm---------------
                # FNet[FBP(Sc+aS), aI] = Icm,  Scm = FP[Icm]
                self.Icm, self.Scm = self.CombineNet(self.Sc, self.aS, self.aI)
                self.sys_art = self.Icm - self.Ic

                # ------------Generator: Icm->Ic'---------------
                _, self.aS_bar, self.Iscmc, self.Icmc, self.aI_bar = self.DecompoNet(self.Scm, self.Mask)
                self.sys_art_bar =  self.Icm - self.Icmc

                # ------------Generator: Imc->Im'---------------
                Smc = self.FPtool(self.Imc).mul(self.dataset.imPixScale)
                self.Imcm, _ = self.CombineNet(Smc, self.aS_bar, self.aI_bar)
                ############ model forward end ##################


                ############ model gan loss ##################
                # -----------GA & GB----------------
                self.set_requires_grad([self.netD_Xa,self.netD_Xc],False)
                self.optimizer_G.zero_grad()
                self.Generator_backward()
                self.optimizer_G.step()

                # -----------Da & Dc----------------
                self.set_requires_grad([self.netD_Xa, self.netD_Xc], True)
                self.optimizer_D.zero_grad()
                self.D_Xa_backward()
                self.D_Xc_backward()
                self.optimizer_D.step()

                ################show the train loss ###################
                temp_GAN_loss.append(self.loss_G.item())
                temp_Dis_loss.append(self.loss_D_Xc.item()+self.loss_D_Xa.item())
                loop.set_description(f'Epoch [{self.opt.epochs}/{epoch}]')
                loop.set_postfix(GANLoss=self.loss_G.item(), G_Xa_Loss=self.loss_G_Xa.item(),
                                 G_Xc_Loss=self.loss_G_Xc.item(), loss_D_Xc=self.loss_D_Xc.item(),
                                 loss_D_Xa=self.loss_D_Xa.item(), loss_cycle=self.L_cycle.item(),
                                 loss_LI=self.loss_idt_LIMAR.item())

            #updata the lr scheduler
            # self.gen_writer.add_scalar('loss/gen_whole_loss', np.mean(temp_GAN_loss), epoch)
            # self.gen_writer.add_scalar('loss/dis_whole_loss', np.mean(temp_Dis_loss), epoch)
            self.GAN_loss_logger[epoch, 0] = np.mean(temp_GAN_loss)
            self.Dis_loss_logger[epoch, 0] = np.mean(temp_Dis_loss)
            self.updata_lr_scheduler()

            if (epoch) % self.opt.logger_freq == 0:
                if self.val_loder:
                    self.validation(epoch)


            if (epoch)%self.opt.save_epoch_freq==0:
                self._saveModel(epoch)
                loss_logger = {'GAN_loss': self.GAN_loss_logger,'Dis_loss':self.Dis_loss_logger,
                               'Val_loss':self.Val_loss_logger}
                savemat('{:s}/trainloss.mat'.format(self.opt.loggerpath), mdict=loss_logger)


    def validation(self, epoch):
        dataType = torch.float32
        self._eval_mode()
        with torch.no_grad():
            # Xc, Xa,_, Mask, Sc, Sm, SLI
            mse_losses = []
            output_img = []
            output_sino = []
            i = 0
            for Xc, Xa, _, Mask, Scc, Sma, _ in self.val_loder:
                torch.cuda.empty_cache()
                Xc = Xc.to(device=self.device, dtype=dataType)
                Xa = Xa.to(device=self.device, dtype=dataType)
                Mask = Mask.to(device=self.device, dtype=dataType)
                Sma = Sma.to(device=self.device, dtype=dataType)
                Scc = Scc.to(device=self.device, dtype=dataType)
                Ssc, aS, X_sc1, X_ac1, aI = self.DecompoNet(Sma, Mask)
                loss = self.criterion_mse(Xc, X_ac1)
                Xaca, _ = self.CombineNet(Scc, aS, aI)
                if i==2:
                    output_img = torch.cat([Xc, Xaca, Xa, X_sc1, X_ac1],dim=2)
                    output_sino = torch.cat([Ssc/5.0, aS/2.0],dim=2)
                    # self.get_visual('{:s}/png/'.format(self.opt.loggerpath), epoch, output_img, n_rows=1)
                elif i==8:
                    img = torch.cat([Xc, Xaca, Xa, X_sc1, X_ac1], dim=2)
                    output_img = torch.cat([output_img, img], dim=0)
                    img = torch.cat([Ssc/5.0, aS/2.0], dim=2)
                    output_sino = torch.cat([output_sino, img], dim=0)
                i = i + 1

                mse_losses.append(loss.item())
            self.get_visual('{:s}/png/'.format(self.opt.loggerpath), epoch, output_img,n_rows=1)
            self.get_visual('{:s}/png2/'.format(self.opt.loggerpath), epoch, output_sino, n_rows=1, normalize=False)
        # self.gen_writer.add_scalar('loss/val_mse_loss', np.mean(mse_losses), 10)
        self.Val_loss_logger[epoch, 0] = np.mean(mse_losses)
